{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4p_DvtT7sOIr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Import all other necessary libraries. Your code below ...\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjKF0nIMwz8_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define a dictionary that uses root_dir as the argument to \n",
    "def make_Dictionary(root_dir):\n",
    "#make an empty list to pass through and fill the dictionary variable\n",
    "  all_words = []\n",
    "#use os module to create an email variable that concatenates the dictionary argument root_dir file path \n",
    "##and f file path to get a string looped through and get all the files and directories in the root_dir path\n",
    "##with the os.listdir method\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "#create for loop that loops through email variable \n",
    "  for mail in emails:\n",
    "##use the with command in the first for loop to make sure files are open and closed correctly \n",
    "    with open(mail) as m:\n",
    "##make a nested for loop to read through the strings received in m to open the mail\n",
    "      for line in m:\n",
    "##create word variable that splits strings \n",
    "        words = line.split()\n",
    "## add all words into the words variable that split the text\n",
    "        all_words += words\n",
    "##create dictionary variable that holds the counting of repeated elements in all_words variable\n",
    "  dictionary = Counter(all_words)\n",
    "## make a variable for the list of elements (words) you want removed\n",
    "  list_to_remove = list(dictionary)\n",
    "##make another for loop to go through the list to remove variable\n",
    "  for item in list_to_remove:\n",
    "##create if statement to determine if the item in the list to remove is alphabetical\n",
    "    if item.isalpha() == False:\n",
    "##if the element in the list to remove is false, then it should be deleted\n",
    "      del dictionary[item]\n",
    "##if the length of a numeric element in the list to be removed variable is numeric, then it should be deleted\n",
    "    elif len(item) == 1:\n",
    "##update the dictionary variable to mean 3000 most common words in the dictionary\n",
    "      del dictionary[item]\n",
    "  dictionary = dictionary.most_common(3000)\n",
    "#have the function return all the words \n",
    "  return dictionary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmVW5xNlyOFc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define a function that will extract features and use the mail_dir (mail directory) parameter\n",
    "def extract_features(mail_dir):\n",
    "#use os module to create a files variable that concatenates the function argument mail_dir file path \n",
    "##and fi file path to get all the files and directories in the mail_dir (mail directory) path and fi path\n",
    "##with the os.listdir method \n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "##create features matrix with numpy zeros function with length of the files, \n",
    "##the matrix will be the length of the file with 3000 0 each\n",
    "  features_matrix = np.zeros((len(files),3000))\n",
    "##create variable train labels for train model to be used later, the train_lables are zeros with the length of the files\n",
    "##that is the concatenation of mail directory path and the list directory\n",
    "  train_labels = np.zeros(len(files))\n",
    "##count and docID are encoding?\n",
    "  count = 1;\n",
    "  docID = 0;\n",
    "##create for loop for files variable as it was done for the mail variable in previous cell to\n",
    "  for fil in files:\n",
    "    with open(fil) as fi:\n",
    "##open the file fil and alias it as fi - fi was used to define files in lines of code above\n",
    "##create a nested for loop and enumerate to count the objects \n",
    "      for i, line in enumerate(fi):\n",
    "##make if statement that says if i ==2 and words is the same variable in the cell above to get the words separate \n",
    "        if i ==2:\n",
    "          words = line.split()\n",
    "##make another for loop to pass labels through the variable train_labels\n",
    "          for word in words:\n",
    "            wordID = 0\n",
    "## create for loop to count the objects and take dictionary as a parameter\n",
    "            for i, d in enumerate(dictionary):\n",
    "##if statement with d index 0 to equal and change wordID to equal letter i \n",
    "              if d[0] == word:\n",
    "                wordID = i\n",
    "## create a variable that counts the word in that iterates in words\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "##make the train data labels equal to 0\n",
    "      train_labels[docID] = 0;\n",
    "#make file path tokens (individual words) by split fil with \\\\ to take the correct paths\n",
    "      filepathTokens = fil.split('\\\\')\n",
    "#make the last token (word) to be filepathtokens indexed? to the length of filepathtokens minus 1\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "#create an if statement for the last token to identify if starts with string spmsg, if it does then\n",
    "#make trains_labels[docID] = 1 and a 1 to the count variable, and add a 1 to the docID variable\n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        train_labels[docID] = 1;\n",
    "        count = count + 1\n",
    "      docID = docID + 1\n",
    "#finally return the features matrix and the train labels for your data\n",
    "  return features_matrix, train_labels                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoq-rE7Mx0pp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
    "TRAIN_DIR = './train-mails'\n",
    "TEST_DIR = './test-mails'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary for your train directory \n",
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "#print what you're doing with the emails by making this dictionary\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "#features- matrix x train labels y train\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
    "#test features matrix x test test labels is y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW SELECT ML ALGORITHM#importing the Naive Bayes algorithm module Gaussian which is used in classification; it assumes that features follow normal distribution\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "# using Gaussian Naive Bayes Algorithm\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Gaussian Naive Bayes algorithm .....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL USING TRAINING DATASET \"Features (features_matrix)\" and \"Outcome (labels)\"\n",
    "# Training Naive bayes classifier\n",
    "print (\"Training Model using Gaussian Naive Bayes algorithm .....\")\n",
    "model.fit(features_matrix, labels)\n",
    "print (\"Training completed\")\n",
    "\n",
    "# TEST THE TRAINED MODEL BY USING THE MODEL TO PREDICT FROM THE TEST DATA \"Features (X_test)\"\n",
    "#Test the unseen passangers from test dataset\n",
    "print (\"testing trained model to predict Test Data labels\")\n",
    "#the y_predicted variable is made to compare the test data with the predicted data to able to see the accuracy of the model \n",
    "y_predicted = model.predict(test_features_matrix)\n",
    "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "\n",
    "#print accuracy of the model\n",
    "#In multilabel classification, this function computes subset accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Accuracy score is just percentage of correct predictions\n",
    "print(accuracy_score(test_labels, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
